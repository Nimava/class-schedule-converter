import pandas as pd
import os
import re
from math import ceil
from openpyxl import load_workbook, Workbook
from openpyxl.utils import get_column_letter
from openpyxl.comments import Comment
from openpyxl.styles import Alignment, Font, PatternFill
import hashlib
import tkinter as tk
from tkinter import filedialog, messagebox
import sys
import tempfile

def show_welcome_message():
    """Show welcome message before file selection"""
    root = tk.Tk()
    root.withdraw()
    
    welcome_text = """Ø¨Ø±Ù†Ø§Ù…Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒØ§Ø± Ø¨Ù‡ Ø§Ú©Ø³Ù„ Ú©Ø§Ø´ÛŒ Ú©Ù„Ø§Ø³Ù‡Ø§

Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ù…Ú©Ø§Ù† ØªØºÛŒÛŒØ± Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒØ§Ø± Ø¯Ø± Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒØŒ Ù„Ø·ÙØ§ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…Ø§ÛŒÛŒØ¯.

Ù†Ø³Ø®Ù‡ 1.3 - Ø¨Ù‡Ù…Ù† 1404 - Ù†ÛŒÙ…Ø§ ÙˆØ²ÛŒØ±ÛŒ"""
    
    messagebox.showinfo("Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯", welcome_text)

def select_input_file():
    """Open file dialog to select input CSV file"""
    root = tk.Tk()
    root.withdraw()  # Hide the main window
    
    file_path = filedialog.askopenfilename(
        title="Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ CSV Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯",
        filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
    )
    
    return file_path

def select_output_file():
    """Open file dialog to select output Excel file location"""
    root = tk.Tk()
    root.withdraw()  # Hide the main window
    
    file_path = filedialog.asksaveasfilename(
        title="Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù†Ù‡Ø§ÛŒÛŒ",
        defaultextension=".xlsx",
        filetypes=[("Excel files", "*.xlsx"), ("All files", "*.*")]
    )
    
    return file_path

def phase1_extract_data(input_file, temp_output_file):
    """Phase 1: Extract important data from CSV and save to Excel"""
    print("ðŸ“– Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV ...")
    
    try:
        # ==== Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ ====
        df = pd.read_csv(input_file, encoding='utf-8-sig')
        print(f"âœ… ÙØ§ÛŒÙ„ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: {len(df)}")
        
        # ==== Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ ====
        selected_columns = {
            'Ù†Ø§Ù… Ø¯Ø±Ø³': 2,           # C
            'Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø±Ø³': 0,      # A
            'ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÛŒ': 11,        # L
            'ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÛŒ': 12,        # M
            'Ù…Ú©Ø§Ù†': 22,             # W
            'Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ': 43,      # AR
            'Ù…Ù‚Ø·Ø¹': 53,             # BB
            'ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÛŒ': 57,   # BF
            'Ù†ÛŒÙ…â€ŒØ³Ø§Ù„': 59,          # BH
            'Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯': 68,        # BQ
            'Ø±Ø´ØªÙ‡': 70,             # BS
            'Ø±ÙˆØ²': 72,              # BU
            'Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹': 73,        # BV
            'Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†': 74,       # BW
            'ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³': 71   # BT - Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
        }
        
        # ==== Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ====
        df_selected = df.iloc[:, list(selected_columns.values())].copy()
        df_selected.columns = list(selected_columns.keys())
        
        # ==== Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ====
        def normalize_text(s):
            return (
                str(s)
                .replace('\u200c', '')   # Ø­Ø°Ù Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡
                .replace('ÙŠ', 'ÛŒ')       # ÛŒ Ø¹Ø±Ø¨ÛŒ â†’ ÙØ§Ø±Ø³ÛŒ
                .replace('Ùƒ', 'Ú©')       # Ú© Ø¹Ø±Ø¨ÛŒ â†’ ÙØ§Ø±Ø³ÛŒ
                .replace('â€Œ', '')        # Ø­Ø°Ù ZWNJ Ø§Ø¶Ø§ÙÛŒ
                .strip()
            )
        
        df_selected = df_selected.fillna("").astype(str)
        
        # NEW: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ø³ØªÙˆÙ† ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ Ø§Ú¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ² Ùˆ Ø³Ø§Ø¹Øª Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ù†Ø¯
        def extract_from_calendar(calendar_text):
            """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ²ØŒ Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ø§Ø² Ù…ØªÙ† ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³"""
            if not calendar_text or calendar_text.strip() == "":
                return "", "", ""
            
            text = str(calendar_text).strip()
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ù‚Ø¨Ù„ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´
            text = normalize_text(text)
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø±ÙˆØ² Ø¨Ø§ Ø§Ù„Ú¯ÙˆÛŒ Ø¯Ù‚ÛŒÙ‚
            day = ""
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² regex Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªÙ…Ø§Ù… Ø§Ø´Ú©Ø§Ù„ Ù…Ù…Ú©Ù†
            patterns = [
                (r'^Ø´Ù†Ø¨Ù‡', 'Ø´Ù†Ø¨Ù‡'),
                (r'^ÛŒÚ©Ø´Ù†Ø¨Ù‡', 'ÛŒÚ©Ø´Ù†Ø¨Ù‡'),
                (r'^Ø¯ÙˆØ´Ù†Ø¨Ù‡', 'Ø¯ÙˆØ´Ù†Ø¨Ù‡'),
                (r'^Ø³Ù‡[â€Œ_\s]*Ø´Ù†Ø¨Ù‡', 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡'),  # Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ØŒ Ø³Ù‡_Ø´Ù†Ø¨Ù‡ØŒ Ø³Ù‡ Ø´Ù†Ø¨Ù‡ØŒ Ø³Ù‡Ø´Ù†Ø¨Ù‡
                (r'^Ú†Ù‡Ø§Ø±[â€Œ_\s]*Ø´Ù†Ø¨Ù‡', 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡'),  # Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡ØŒ Ú†Ù‡Ø§Ø±_Ø´Ù†Ø¨Ù‡ØŒ Ú†Ù‡Ø§Ø± Ø´Ù†Ø¨Ù‡
                (r'^Ù¾Ù†Ø¬[â€Œ_\s]*Ø´Ù†Ø¨Ù‡', 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡'),  # Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡ØŒ Ù¾Ù†Ø¬_Ø´Ù†Ø¨Ù‡ØŒ Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡ØŒ Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡
                (r'^Ø¬Ù…Ø¹Ù‡', 'Ø¬Ù…Ø¹Ù‡')
            ]
            
            for pattern, day_name in patterns:
                if re.match(pattern, text, re.UNICODE):
                    day = day_name
                    break
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø§Ø¹Øªâ€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆÛŒ "Ø³Ø§Ø¹Øª ØªØ§ Ø³Ø§Ø¹Øª"
            time_pattern = r'(\d{1,2}[:\.]\d{2})\s*ØªØ§\s*(\d{1,2}[:\.]\d{2})'
            time_match = re.search(time_pattern, text)
            
            start_time = ""
            end_time = ""
            
            if time_match:
                start_time = time_match.group(1).replace('.', ':')
                end_time = time_match.group(2).replace('.', ':')
            
            return day, start_time, end_time
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ø±Ø¯ÛŒÙ
        for idx, row in df_selected.iterrows():
            # Ø§Ú¯Ø± Ø±ÙˆØ² ÛŒØ§ Ø³Ø§Ø¹Øª Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø³ØªÙˆÙ† ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†
            if (row['Ø±ÙˆØ²'].strip() == "" or 
                row['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'].strip() == "" or 
                row['Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†'].strip() == ""):
                
                calendar_text = row['ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³']
                day_from_cal, start_from_cal, end_from_cal = extract_from_calendar(calendar_text)
                
                if row['Ø±ÙˆØ²'].strip() == "" and day_from_cal:
                    df_selected.at[idx, 'Ø±ÙˆØ²'] = day_from_cal
                
                if row['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'].strip() == "" and start_from_cal:
                    df_selected.at[idx, 'Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'] = start_from_cal
                
                if row['Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†'].strip() == "" and end_from_cal:
                    df_selected.at[idx, 'Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†'] = end_from_cal
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø±ÙˆØ²Ù‡Ø§ (Ù‡Ù…Ø§Ù†Ù†Ø¯ Ù‚Ø¨Ù„)
        df_selected['Ø±ÙˆØ²'] = df_selected['Ø±ÙˆØ²'].apply(normalize_text)
        
        # ==== Ù†Ú¯Ø§Ø´Øª Ø¯Ù‚ÛŒÙ‚ Ø§Ø³Ø§Ù…ÛŒ Ø±ÙˆØ²Ù‡Ø§ ====
        day_map = {
            'Ø´Ù†Ø¨Ù‡': 'Ø´Ù†Ø¨Ù‡',
            'ÛŒÚ©Ø´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÙŠÚ©Ø´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÙŠÙƒØ´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÛŒÙƒØ´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'Ø¯ÙˆØ´Ù†Ø¨Ù‡': 'Ø¯ÙˆØ´Ù†Ø¨Ù‡',
            'Ø³Ù‡ Ø´Ù†Ø¨Ù‡': 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡',
            'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡': 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡',
            'Ø³Ù‡Ø´Ù†Ø¨Ù‡': 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡',  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡': 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡',
            'Ú†Ù‡Ø§Ø± Ø´Ù†Ø¨Ù‡': 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ú†Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',      # Ø­Ø§Ù„Øª Ø§Ø´ØªØ¨Ø§Ù‡ ØªØ§ÛŒÙ¾ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ
            'Ù¾Ù†Ú† Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ø¬Ù…Ø¹Ù‡': 'Ø¬Ù…Ø¹Ù‡'
        }
        
        # ðŸ”¹ Ù†Ú¯Ø§Ø´Øª Ø¨Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ (Ù†Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯Ø±ÙˆÙ† Ø±Ø´ØªÙ‡)
        df_selected['Ø±ÙˆØ²'] = df_selected['Ø±ÙˆØ²'].apply(
            lambda x: day_map[x] if x in day_map else x
        )
        
        # ==== Ù„ÛŒØ³Øª Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± ====
        days = ['Ø´Ù†Ø¨Ù‡', 'ÛŒÚ©Ø´Ù†Ø¨Ù‡', 'Ø¯ÙˆØ´Ù†Ø¨Ù‡', 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡', 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡', 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡', 'Ø¬Ù…Ø¹Ù‡']
        
        # ==== ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø´ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø²Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ====
        sheets = {}
        for day in days:
            subset = df_selected[df_selected['Ø±ÙˆØ²'] == day].copy()
            if not subset.empty:
                # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹
                subset['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨'] = subset['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'].str.extract(r'(\d+)').astype(float)
                subset = subset.sort_values(by='Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨', ascending=True).drop(columns=['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨'])
                sheets[day] = subset
        
        # ==== Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø±ÙˆØ² Ù†Ø§Ù…Ø´Ø®Øµ ====
        unknown = df_selected[~df_selected['Ø±ÙˆØ²'].isin(days)]
        if not unknown.empty:
            sheets['Ù†Ø§Ù…Ø´Ø®Øµ'] = unknown
        
        # ==== Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ ====
        with pd.ExcelWriter(temp_output_file, engine='openpyxl') as writer:
            for day, subset in sheets.items():
                subset.to_excel(writer, sheet_name=day[:30], index=False)
        
        print("âœ… ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù…ÙˆÙ‚Øª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯:", temp_output_file)
        print("ðŸ“… Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:", list(sheets.keys()))
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ§Ø² Ø§ÙˆÙ„: {e}")
        return False
        
def phase2_create_schedule(temp_file, final_output_file):
    """Phase 2: Create class schedule tables from the temporary Excel file"""
    
    # Configuration
    SLOT_MIN = 30   # minutes
    DAY_START_MIN = 8 * 60  # start at 08:00
    
    if not os.path.exists(temp_file):
        raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª ÛŒØ§ÙØª Ù†Ø´Ø¯: {temp_file}")
    
    print("Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª:", temp_file)
    xls = pd.ExcelFile(temp_file)
    print("Ø´ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:", xls.sheet_names)
    
    # helper: normalize time string -> minutes
    def to_minutes(t):
        if pd.isna(t) or str(t).strip() == "":
            return None
        s = str(t).strip()
        s = s.translate(str.maketrans('Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹','0123456789'))
        s = s.replace('.', ':').replace('ï¼š', ':')
        # if input like "8" -> "8:00"
        if ':' not in s and s.isdigit() and len(s) <= 2:
            try:
                return int(s) * 60
            except:
                return None
        if ':' in s:
            parts = s.split(':')
            try:
                h = int(parts[0])
                m = int(parts[1]) if len(parts) > 1 and parts[1].isdigit() else 0
                return h*60 + m
            except:
                return None
        # fallback try digits-only like "0830"
        if s.isdigit() and len(s) in (3,4):
            if len(s)==3: s = '0'+s
            hh = int(s[:-2]); mm = int(s[-2:])
            return hh*60 + mm
        return None
    
    def minute_label(m):
        hh = m//60; mm = m%60
        return f"{hh:02d}:{mm:02d}"
    
    # helper: find columns robustly
    def find_col(df_cols, candidates):
        for cand in candidates:
            for c in df_cols:
                if str(c).strip() == cand:
                    return c
        for cand in candidates:
            for c in df_cols:
                if cand in str(c):
                    return c
        return None
    
    # generate consistent light color based on course name
    def get_light_color(course_name):
        """Generate a consistent light pastel color based on course name"""
        if not course_name:
            return "FFFFFF"
        # Use hash to get consistent color for same course
        hash_val = int(hashlib.md5(course_name.encode()).hexdigest()[:8], 16)
        
        # Generate pastel colors using HSL technique (light colors)
        hues = [0, 30, 60, 120, 180, 240, 300]  # Red, Orange, Yellow, Green, Cyan, Blue, Magenta
        hue = hues[hash_val % len(hues)]
        
        # Light pastel colors (high lightness, medium saturation)
        if hue == 0:    # Red
            return "FFE6E6"  # Very light red
        elif hue == 30:  # Orange
            return "FFE8CC"  # Very light orange
        elif hue == 60:  # Yellow
            return "FFF9C4"  # Very light yellow
        elif hue == 120: # Green
            return "E6F7E6"  # Very light green
        elif hue == 180: # Cyan
            return "E6F7F7"  # Very light cyan
        elif hue == 240: # Blue
            return "E6E6FF"  # Very light blue
        else:           # Magenta
            return "F7E6F7"  # Very light magenta
    
    # build slots globally as needed per sheet (end depends on data)
    def build_slots(min_start, max_end):
        # ensure start is DAY_START_MIN
        start = DAY_START_MIN
        # round end up to nearest slot
        end = ((max_end + SLOT_MIN - 1)//SLOT_MIN)*SLOT_MIN
        if end <= start:
            end = start + 10 * 60  # fallback to 10 hours
        return list(range(start, end, SLOT_MIN))
    
    # collect which sheets we will build tables for
    weekday_names = ['Ø´Ù†Ø¨Ù‡','ÛŒÚ©Ø´Ù†Ø¨Ù‡','Ø¯ÙˆØ´Ù†Ø¨Ù‡','Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡','Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡','Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡','Ø¬Ù…Ø¹Ù‡']
    
    # Load the existing workbook (don't create a new one)
    wb = load_workbook(temp_file)
    
    # remove prior phase2 sheets if they exist (start fresh)
    for s in wb.sheetnames[:]:
        if s.startswith("Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ "):
            wb.remove(wb[s])
    
    # iterate through Phase1 weekday sheets
    for sheet in xls.sheet_names:
        if sheet not in weekday_names:
            continue
        print("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´ÛŒØª:", sheet)
        df = pd.read_excel(xls, sheet_name=sheet)
        if df.empty:
            print(" -> Ø´ÛŒØª Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ø±Ø¯ Ø´Ø¯.")
            continue
        
        # find relevant columns robustly
        cols = list(df.columns)
        col_room = find_col(cols, ['Ù…Ú©Ø§Ù†','Ù†Ø§Ù… Ù…ÙƒØ§Ù†','Ù…ÙƒØ§Ù†'])
        col_course = find_col(cols, ['Ù†Ø§Ù… Ø¯Ø±Ø³','Ù†Ø§Ù… Ú©Ù„Ø§Ø³ Ø¯Ø±Ø³','Ù†Ø§Ù… Ú©Ù„Ø§Ø³'])
        col_teacher = find_col(cols, ['Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯','Ù†Ø§Ù… ÙƒØ§Ù…Ù„ Ø§Ø³ØªØ§Ø¯','PR S_FNAME','Ù†Ø§Ù… ÙƒØ§Ù…Ù„'])
        col_code = find_col(cols, ['Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø±Ø³','Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡','Ú©Ø¯ Ø¯Ø±Ø³'])
        col_unit_th = find_col(cols, ['ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÛŒ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÙŠ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯'])
        col_unit_pr = find_col(cols, ['ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÛŒ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÙŠ'])
        col_group = find_col(cols, ['Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ','Ù†Ø§Ù… Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÙŠ','Ú¯Ø±ÙˆÙ‡'])
        col_degree = find_col(cols, ['Ù…Ù‚Ø·Ø¹'])
        col_reg = find_col(cols, ['ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÛŒ','ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÙŠ','ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…'])
        col_M = find_col(cols, ['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹','Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ú©Ù„Ø§Ø³','M','BV'])
        col_N = find_col(cols, ['Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†','Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù† Ú©Ù„Ø§Ø³','N','BW'])
        
        if col_room is None:
            print(" -> Ø³ØªÙˆÙ† 'Ù…Ú©Ø§Ù†' ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø±Ø¯ Ø´Ø¯.")
            continue
        
        # normalize textual columns
        for c in [col_room, col_course, col_teacher, col_code, col_unit_th, col_unit_pr, col_group, col_degree, col_reg]:
            if c is not None and c in df.columns:
                df[c] = df[c].fillna("").astype(str).str.replace('\u200c','').str.strip()
        # times
        if col_M in df.columns:
            df['_M_min'] = df[col_M].apply(to_minutes)
        else:
            df['_M_min'] = None
        if col_N in df.columns:
            df['_N_min'] = df[col_N].apply(to_minutes)
        else:
            df['_N_min'] = None
        
        # drop exact duplicates (same code, same room, same times)
        keycols = [c for c in [col_code, col_course, col_teacher, col_room, col_M, col_N] if c is not None]
        if keycols:
            df = df.drop_duplicates(subset=keycols)
        
        # determine slots (start at 08:00, end by max end)
        starts = df['_M_min'].dropna().tolist()
        ends = df['_N_min'].dropna().tolist()
        max_end = max(ends) if ends else (20*60)
        slots = build_slots(DAY_START_MIN, max_end)
        slot_labels = [minute_label(s) for s in slots]
        
        # prepare rooms: one row per unique room (exact string)
        rooms = df[col_room].fillna("").astype(str).unique().tolist()
        
        # NEW: Sort rooms by extracting numeric part
        def extract_number(room_name):
            """Extract numeric part from room name for sorting"""
            # Find all numbers in the string
            numbers = re.findall(r'\d+', room_name)
            if numbers:
                # Use the first number found
                return int(numbers[0])
            return 0  # Default for rooms without numbers
        
        # Sort rooms based on extracted number
        rooms.sort(key=lambda x: extract_number(x))
        
        # build a grid: dict room -> list per slot (None or list of entries)
        grid = {room: [None]*len(slots) for room in rooms}
        
        # fill grid: for each record mark slot indices that fully fit inside [M,N)
        for idx, row in df.iterrows():
            room = str(row[col_room])
            start = row.get('_M_min', None)
            end = row.get('_N_min', None)
            if start is None or end is None:
                continue
            
            # find start_idx: first slot s.t. slots[i] <= start < slots[i]+SLOT_MIN
            start_idx = None
            for i, s in enumerate(slots):
                if s <= start < s + SLOT_MIN:
                    start_idx = i
                    break
            if start_idx is None:
                start_idx = min(range(len(slots)), key=lambda k: abs(slots[k]-start))
            
            # end_idx: last index where slot_start + SLOT_MIN <= end (fully contained)
            end_idx = None
            for i, s in enumerate(slots):
                if s + SLOT_MIN <= end:
                    end_idx = i
            if end_idx is None or end_idx < start_idx:
                continue
            
            # Create unique entry identifier to avoid duplicates
            entry_id = f"{row[col_course] if col_course else ''}|{row[col_teacher] if col_teacher else ''}|{row[col_code] if col_code else ''}"
            
            # Create entry data
            entry_data = {
                'course': row[col_course] if col_course else "",
                'teacher': row[col_teacher] if col_teacher else "",
                'code': row[col_code] if col_code else "",
                'unit_th': row[col_unit_th] if col_unit_th else "",
                'unit_pr': row[col_unit_pr] if col_unit_pr else "",
                'group': row[col_group] if col_group else "",
                'degree': row[col_degree] if col_degree else "",
                'reg': row[col_reg] if col_reg else "",
                'M': row[col_M] if col_M else "",
                'N': row[col_N] if col_N else "",
                'entry_id': entry_id
            }
            
            # assign entry to each slot in range
            for k in range(start_idx, end_idx+1):
                if grid[room][k] is None:
                    grid[room][k] = []
                
                # Check if this exact entry already exists to avoid duplicates
                existing_entry_ids = [e['entry_id'] for e in grid[room][k]]
                if entry_id not in existing_entry_ids:
                    grid[room][k].append(entry_data)
        
        # Create phase2 sheet
        out_name = f"Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ {sheet}"
        out_name = out_name[:31]
        ws = wb.create_sheet(title=out_name)
        
        # Title row merged
        total_cols = 1 + len(slot_labels)
        ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=total_cols)
        title_cell = ws.cell(row=1, column=1, value=f"Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ {sheet}")
        title_cell.font = Font(size=14, bold=True)
        title_cell.alignment = Alignment(horizontal="center", vertical="center")
        
        # header row (slot labels) in row 2
        ws.cell(row=2, column=1, value="Ù…Ú©Ø§Ù† / Ø³Ø§Ø¹Øª").font = Font(bold=True)
        for j, lbl in enumerate(slot_labels, start=2):
            c = ws.cell(row=2, column=j, value=lbl)
            c.alignment = Alignment(horizontal="center", vertical="center")
            c.font = Font(size=9)
        
        # write room rows beginning at row 3
        start_row = 3
        for i, room in enumerate(rooms):
            r = start_row + i
            ws.cell(row=r, column=1, value=room)
            ws.cell(row=r, column=1).alignment = Alignment(horizontal="center", vertical="center")
            ws.row_dimensions[r].height = 22
            
            # merge contiguous slots with same content
            j = 0
            while j < len(slots):
                cell_entries = grid[room][j]
                if not cell_entries:
                    j += 1
                    continue
                
                # Find contiguous slots with identical content
                k = j
                while k+1 < len(slots) and grid[room][k+1] == cell_entries:
                    k += 1
                
                excel_start = 2 + j
                excel_end = 2 + k
                
                # Merge cells
                if excel_end > excel_start:
                    ws.merge_cells(start_row=r, start_column=excel_start, end_row=r, end_column=excel_end)
                
                anchor = ws.cell(row=r, column=excel_start)
                
                # Display content (avoid duplicates)
                unique_entries = []
                seen_entry_ids = set()
                for ent in cell_entries:
                    if ent['entry_id'] not in seen_entry_ids:
                        unique_entries.append(ent)
                        seen_entry_ids.add(ent['entry_id'])
                
                # Format display text - only show unique entries
                display_lines = []
                tooltip_lines = []
                
                for ent in unique_entries:
                    display_line = f"{ent['course']} â€” {ent['teacher']}"
                    display_lines.append(display_line)
                    
                    # Simplified tooltip - removed Ú¯Ø±ÙˆÙ‡ and Ù…Ù‚Ø·Ø¹ to save space
                    tooltip_text = (
                        f"Ø¯Ø±Ø³: {ent['course']}\n"
                        f"Ø§Ø³ØªØ§Ø¯: {ent['teacher']}\n"
                        f"Ú©Ø¯: {ent['code']}\n"
                        f"ÙˆØ§Ø­Ø¯: {ent['unit_th']}(Ù†) + {ent['unit_pr']}(Ø¹)\n"
                        f"Ø«Ø¨Øªâ€ŒÙ†Ø§Ù…: {ent['reg']}\n"
                        f"Ø³Ø§Ø¹Øª: {ent['M']} - {ent['N']}"
                    )
                    tooltip_lines.append(tooltip_text)
                
                # Only show unique display lines (avoid duplicates in display)
                unique_display_lines = list(set(display_lines))
                anchor.value = "\n".join(unique_display_lines)
                anchor.alignment = Alignment(wrap_text=True, horizontal="center", vertical="center")
                
                # Add tooltip comment with increased height
                if tooltip_lines:
                    try:
                        comment_text = "\n" + "â”€" * 30 + "\n".join(tooltip_lines)
                        anchor.comment = Comment(comment_text, "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ³Ø§Ø²")
                        anchor.comment.width = 350  # Increased width
                        anchor.comment.height = 200  # Increased height for better visibility
                    except Exception as e:
                        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ú©Ø§Ù…Ù†Øª: {e}")
                
                # Apply light color based on course name
                if unique_entries:
                    first_course = unique_entries[0]['course']
                    color_hex = get_light_color(first_course)
                    fill = PatternFill(start_color=color_hex, end_color=color_hex, fill_type="solid")
                    anchor.fill = fill
                    
                    # Apply same fill to all merged cells
                    for col in range(excel_start, excel_end + 1):
                        ws.cell(row=r, column=col).fill = fill
                
                j = k + 1
        
        # Adjust column widths (reduced as requested)
        ws.column_dimensions[get_column_letter(1)].width = 25  # Reduced room column width
        for col_idx in range(2, 2 + len(slot_labels)):
            col_letter = get_column_letter(col_idx)
            ws.column_dimensions[col_letter].width = 8  # Reduced from 20 to 8 (less than half)
        
        # center alignment for header area
        for row in ws.iter_rows(min_row=2, max_row=2, min_col=1, max_col=1+len(slot_labels)):
            for c in row:
                c.alignment = Alignment(horizontal="center", vertical="center")
    
    print("Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ:", final_output_file)
    wb.save(final_output_file)
    print("âœ… Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

def main():
    """Main function to run the complete process"""
    print("ðŸŽ“ Ø¨Ø±Ù†Ø§Ù…Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ")
    print("=" * 50)
    
    # Show welcome message first
    show_welcome_message()
    
    # Select input CSV file
    input_file = select_input_file()
    if not input_file:
        print("âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯.")
        return
    
    print(f"ðŸ“ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ: {input_file}")
    
    # Select output Excel file
    output_file = select_output_file()
    if not output_file:
        print("âŒ Ù…Ø­Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯.")
        return
    
    print(f"ðŸ“ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    
    # Create temporary file in system temp directory to avoid access issues
    temp_file = os.path.join(tempfile.gettempdir(), "temp_schedule_phase1.xlsx")
    
    try:
        # Phase 1: Extract data from CSV
        print("\nðŸ”¹ Ù…Ø±Ø­Ù„Ù‡ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ CSV...")
        if not phase1_extract_data(input_file, temp_file):
            return
        
        # Phase 2: Create schedule tables
        print("\nðŸ”¹ Ù…Ø±Ø­Ù„Ù‡ 2: Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ...")
        phase2_create_schedule(temp_file, output_file)
        
        print("\nðŸŽ‰ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
        print(f"ðŸ“Š ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {output_file}")
        
        # Show success message
        root = tk.Tk()
        root.withdraw()
        messagebox.showinfo("Ù…ÙˆÙÙ‚", f"Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯!\nÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ: {os.path.basename(output_file)}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡: {e}")
        
        # Show error message
        root = tk.Tk()
        root.withdraw()
        messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡:\n{str(e)}")
        
    finally:
        # Clean up temporary file if it exists
        if os.path.exists(temp_file):
            try:
                # Make sure the file is closed before deleting
                import gc
                gc.collect()
                os.remove(temp_file)
                print(f"âœ… ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ù¾Ø§Ú© Ø´Ø¯: {temp_file}")
            except Exception as e:
                print(f"âš ï¸ Ù†ØªÙˆØ§Ù†Ø³Øª ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†Ø¯: {e}")

if __name__ == "__main__":
    main()import gradio as gr
import pandas as pd
import tempfile
import os
import io
import hashlib
from math import ceil
from openpyxl import load_workbook, Workbook
from openpyxl.utils import get_column_letter
from openpyxl.comments import Comment
from openpyxl.styles import Alignment, Font, PatternFill
import re
import atexit
import glob

def cleanup_temp_files():
    """Clean up any remaining temporary files"""
    temp_files = glob.glob("/tmp/*_final.xlsx") + glob.glob("/tmp/*_phase1.xlsx")
    for temp_file in temp_files:
        try:
            if os.path.exists(temp_file):
                os.unlink(temp_file)
                print(f"ðŸ§¹ Cleaned up: {temp_file}")
        except Exception as e:
            print(f"âš ï¸ Could not clean up {temp_file}: {e}")

# Register cleanup function
atexit.register(cleanup_temp_files)

def extract_time_from_calendar(calendar_text):
    """Extract start time from ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ column"""
    if pd.isna(calendar_text) or not calendar_text:
        return None
    
    calendar_str = str(calendar_text).strip()
    
    # Pattern to match time in format "HH:MM ØªØ§ HH:MM"
    time_pattern = r'(\d{1,2}:\d{2})\s*ØªØ§\s*\d{1,2}:\d{2}'
    match = re.search(time_pattern, calendar_str)
    
    if match:
        return match.group(1)  # Return the start time
    
    return None

def phase1_extract_data(input_file, temp_output_file):
    """Phase 1: Extract important data from CSV and save to Excel"""
    try:
        print("ðŸ”¹ Phase 1: Starting data extraction...")
        
        # Read the uploaded file
        if hasattr(input_file, 'name'):  # Gradio file object
            file_path = input_file.name
        else:
            file_path = input_file
            
        print(f"ðŸ”¹ Reading file: {file_path}")
        
        # Determine file type and read
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            print("âœ… CSV file read successfully")
        else:
            df = pd.read_excel(file_path)
            print("âœ… Excel file read successfully")
        
        print(f"âœ… File read successfully. Rows: {len(df)}, Columns: {len(df.columns)}")
        
        # ==== Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ ====
        selected_columns = {
            'Ù†Ø§Ù… Ø¯Ø±Ø³': 2,           # C
            'Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø±Ø³': 0,      # A
            'ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÛŒ': 11,        # L
            'ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÛŒ': 12,        # M
            'Ù…Ú©Ø§Ù†': 22,             # W
            'Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ': 43,      # AR
            'Ù…Ù‚Ø·Ø¹': 53,             # BB
            'ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÛŒ': 57,   # BF
            'Ù†ÛŒÙ…â€ŒØ³Ø§Ù„': 59,          # BH
            'Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯': 68,        # BQ
            'Ø±Ø´ØªÙ‡': 70,             # BS
            'Ø±ÙˆØ²': 72,              # BU
            'Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹': 73,        # BV
            'Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†': 74,       # BW
            'ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³': 71   # BT - Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
        }
        
        # ==== Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ====
        df_selected = df.iloc[:, list(selected_columns.values())].copy()
        df_selected.columns = list(selected_columns.keys())
        
        # ==== Ù¾Ø± Ú©Ø±Ø¯Ù† Ø³Ø§Ø¹Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø®Ø§Ù„ÛŒ Ø§Ø² Ø³ØªÙˆÙ† ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ ====
        print("ðŸ”¹ Checking for empty start times...")
        empty_start_count = df_selected['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'].isna().sum()
        empty_start_count += (df_selected['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'] == '').sum()
        print(f"ðŸ”¹ Found {empty_start_count} empty start times")
        
        if empty_start_count > 0:
            print("ðŸ”¹ Filling empty start times from ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ column...")
            filled_count = 0
            
            for idx, row in df_selected.iterrows():
                start_time = str(row['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹']).strip() if pd.notna(row['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹']) else ""
                calendar_text = row['ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³']
                
                # If start time is empty but we have calendar data
                if not start_time and pd.notna(calendar_text) and str(calendar_text).strip():
                    extracted_time = extract_time_from_calendar(calendar_text)
                    if extracted_time:
                        df_selected.at[idx, 'Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'] = extracted_time
                        filled_count += 1
                        print(f"   â†³ Filled row {idx}: {extracted_time}")
            
            print(f"âœ… Filled {filled_count} empty start times from calendar data")
        
        # ==== Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ====
        def normalize_text(s):
            return (
                str(s)
                .replace('\u200c', '')   # Ø­Ø°Ù Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡
                .replace('ÙŠ', 'ÛŒ')       # ÛŒ Ø¹Ø±Ø¨ÛŒ â†’ ÙØ§Ø±Ø³ÛŒ
                .replace('Ùƒ', 'Ú©')       # Ú© Ø¹Ø±Ø¨ÛŒ â†’ ÙØ§Ø±Ø³ÛŒ
                .replace('â€Œ', '')        # Ø­Ø°Ù ZWNJ Ø§Ø¶Ø§ÙÛŒ
                .strip()
            )
        
        df_selected = df_selected.fillna("").astype(str)
        df_selected['Ø±ÙˆØ²'] = df_selected['Ø±ÙˆØ²'].apply(normalize_text)
        
        # ==== Ù†Ú¯Ø§Ø´Øª Ø¯Ù‚ÛŒÙ‚ Ø§Ø³Ø§Ù…ÛŒ Ø±ÙˆØ²Ù‡Ø§ ====
        day_map = {
            'Ø´Ù†Ø¨Ù‡': 'Ø´Ù†Ø¨Ù‡',
            'ÛŒÚ©Ø´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÙŠÚ©Ø´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÙŠÙƒØ´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'ÛŒÙƒØ´Ù†Ø¨Ù‡': 'ÛŒÚ©Ø´Ù†Ø¨Ù‡',
            'Ø¯ÙˆØ´Ù†Ø¨Ù‡': 'Ø¯ÙˆØ´Ù†Ø¨Ù‡',
            'Ø³Ù‡ Ø´Ù†Ø¨Ù‡': 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡',
            'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡': 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡',
            'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡': 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡',
            'Ú†Ù‡Ø§Ø± Ø´Ù†Ø¨Ù‡': 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ú†Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ù¾Ù†Ú† Ø´Ù†Ø¨Ù‡': 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡',
            'Ø¬Ù…Ø¹Ù‡': 'Ø¬Ù…Ø¹Ù‡'
        }
        
        df_selected['Ø±ÙˆØ²'] = df_selected['Ø±ÙˆØ²'].apply(
            lambda x: day_map[x] if x in day_map else x
        )
        
        # ==== Ù„ÛŒØ³Øª Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± ====
        days = ['Ø´Ù†Ø¨Ù‡', 'ÛŒÚ©Ø´Ù†Ø¨Ù‡', 'Ø¯ÙˆØ´Ù†Ø¨Ù‡', 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡', 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡', 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡', 'Ø¬Ù…Ø¹Ù‡']
        
        # ==== ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø´ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø²Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ====
        sheets = {}
        for day in days:
            subset = df_selected[df_selected['Ø±ÙˆØ²'] == day].copy()
            if not subset.empty:
                # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹
                # ØªØ¨Ø¯ÛŒÙ„ Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
                def time_to_sortable(time_str):
                    if not time_str or str(time_str).strip() == "":
                        return 0
                    try:
                        # ØªØ¨Ø¯ÛŒÙ„ Ø²Ù…Ø§Ù† Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø±ÙˆØ²
                        time_str = str(time_str).strip()
                        time_str = time_str.translate(str.maketrans('Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹', '0123456789'))
                        if ':' in time_str:
                            parts = time_str.split(':')
                            hours = int(parts[0])
                            minutes = int(parts[1]) if len(parts) > 1 else 0
                            return hours * 60 + minutes
                        else:
                            # Ø§Ú¯Ø± ÙÙ‚Ø· Ø¹Ø¯Ø¯ Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ "8")
                            return int(time_str) * 60
                    except:
                        return 0
                
                subset['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨'] = subset['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹'].apply(time_to_sortable)
                subset = subset.sort_values(by='Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨', ascending=True).drop(columns=['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ù…Ø±ØªØ¨'])
                sheets[day] = subset
        
        # ==== Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø±ÙˆØ² Ù†Ø§Ù…Ø´Ø®Øµ ====
        unknown = df_selected[~df_selected['Ø±ÙˆØ²'].isin(days)]
        if not unknown.empty:
            sheets['Ù†Ø§Ù…Ø´Ø®Øµ'] = unknown
        
        # ==== Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ ====
        with pd.ExcelWriter(temp_output_file, engine='openpyxl') as writer:
            for day, subset in sheets.items():
                # Ø­Ø°Ù Ø³ØªÙˆÙ† ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³ Ø§Ø² Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
                subset_to_save = subset.drop(columns=['ØªÙ‚ÙˆÙŠÙ… ÙƒÙ„Ø§Ø³ Ø¯Ø±Ø³'], errors='ignore')
                subset_to_save.to_excel(writer, sheet_name=day[:30], index=False)
        
        print("âœ… ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù…ÙˆÙ‚Øª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯")
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ§Ø² Ø§ÙˆÙ„: {e}")
        import traceback
        print(f"ðŸ” Traceback:\n{traceback.format_exc()}")
        return False

def phase2_create_schedule(temp_file, final_output_file):
    """Phase 2: Create class schedule tables from the temporary Excel file"""
    
    # Configuration
    SLOT_MIN = 30   # minutes
    DAY_START_MIN = 8 * 60  # start at 08:00
    
    if not os.path.exists(temp_file):
        raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª ÛŒØ§ÙØª Ù†Ø´Ø¯: {temp_file}")
    
    print("Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª")
    xls = pd.ExcelFile(temp_file)
    print("Ø´ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:", xls.sheet_names)
    
    # helper: normalize time string -> minutes
    def to_minutes(t):
        if pd.isna(t) or str(t).strip() == "":
            return None
        s = str(t).strip()
        s = s.translate(str.maketrans('Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹','0123456789'))
        s = s.replace('.', ':').replace('ï¼š', ':')
        # if input like "8" -> "8:00"
        if ':' not in s and s.isdigit() and len(s) <= 2:
            try:
                return int(s) * 60
            except:
                return None
        if ':' in s:
            parts = s.split(':')
            try:
                h = int(parts[0])
                m = int(parts[1]) if len(parts) > 1 and parts[1].isdigit() else 0
                return h*60 + m
            except:
                return None
        # fallback try digits-only like "0830"
        if s.isdigit() and len(s) in (3,4):
            if len(s)==3: s = '0'+s
            hh = int(s[:-2]); mm = int(s[-2:])
            return hh*60 + mm
        return None
    
    def minute_label(m):
        hh = m//60; mm = m%60
        return f"{hh:02d}:{mm:02d}"
    
    # helper: find columns robustly
    def find_col(df_cols, candidates):
        for cand in candidates:
            for c in df_cols:
                if str(c).strip() == cand:
                    return c
        for cand in candidates:
            for c in df_cols:
                if cand in str(c):
                    return c
        return None
    
    # generate consistent light color based on course name
    def get_light_color(course_name):
        """Generate a consistent light pastel color based on course name"""
        if not course_name:
            return "FFFFFF"
        # Use hash to get consistent color for same course
        hash_val = int(hashlib.md5(course_name.encode()).hexdigest()[:8], 16)
        
        # Generate pastel colors using HSL technique (light colors)
        hues = [0, 30, 60, 120, 180, 240, 300]  # Red, Orange, Yellow, Green, Cyan, Blue, Magenta
        hue = hues[hash_val % len(hues)]
        
        # Light pastel colors (high lightness, medium saturation)
        if hue == 0:    # Red
            return "FFE6E6"  # Very light red
        elif hue == 30:  # Orange
            return "FFE8CC"  # Very light orange
        elif hue == 60:  # Yellow
            return "FFF9C4"  # Very light yellow
        elif hue == 120: # Green
            return "E6F7E6"  # Very light green
        elif hue == 180: # Cyan
            return "E6F7F7"  # Very light cyan
        elif hue == 240: # Blue
            return "E6E6FF"  # Very light blue
        else:           # Magenta
            return "F7E6F7"  # Very light magenta
    
    # build slots globally as needed per sheet (end depends on data)
    def build_slots(min_start, max_end):
        # ensure start is DAY_START_MIN
        start = DAY_START_MIN
        # round end up to nearest slot
        end = ((max_end + SLOT_MIN - 1)//SLOT_MIN)*SLOT_MIN
        if end <= start:
            end = start + 10 * 60  # fallback to 10 hours
        return list(range(start, end, SLOT_MIN))
    
    # collect which sheets we will build tables for
    weekday_names = ['Ø´Ù†Ø¨Ù‡','ÛŒÚ©Ø´Ù†Ø¨Ù‡','Ø¯ÙˆØ´Ù†Ø¨Ù‡','Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡','Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡','Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡','Ø¬Ù…Ø¹Ù‡']
    
    # Load the existing workbook (don't create a new one)
    wb = load_workbook(temp_file)
    
    # remove prior phase2 sheets if they exist (start fresh)
    for s in wb.sheetnames[:]:
        if s.startswith("Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ "):
            wb.remove(wb[s])
    
    # iterate through Phase1 weekday sheets
    for sheet in xls.sheet_names:
        if sheet not in weekday_names:
            continue
        print("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´ÛŒØª:", sheet)
        df = pd.read_excel(xls, sheet_name=sheet)
        if df.empty:
            print(" -> Ø´ÛŒØª Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ø±Ø¯ Ø´Ø¯.")
            continue
        
        # find relevant columns robustly
        cols = list(df.columns)
        col_room = find_col(cols, ['Ù…Ú©Ø§Ù†','Ù†Ø§Ù… Ù…ÙƒØ§Ù†','Ù…ÙƒØ§Ù†'])
        col_course = find_col(cols, ['Ù†Ø§Ù… Ø¯Ø±Ø³','Ù†Ø§Ù… Ú©Ù„Ø§Ø³ Ø¯Ø±Ø³','Ù†Ø§Ù… Ú©Ù„Ø§Ø³'])
        col_teacher = find_col(cols, ['Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯','Ù†Ø§Ù… ÙƒØ§Ù…Ù„ Ø§Ø³ØªØ§Ø¯','PR S_FNAME','Ù†Ø§Ù… ÙƒØ§Ù…Ù„'])
        col_code = find_col(cols, ['Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø±Ø³','Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡','Ú©Ø¯ Ø¯Ø±Ø³'])
        col_unit_th = find_col(cols, ['ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÛŒ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ù†Ø¸Ø±ÙŠ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯'])
        col_unit_pr = find_col(cols, ['ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÛŒ','ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ø¹Ù…Ù„ÙŠ'])
        col_group = find_col(cols, ['Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ','Ù†Ø§Ù… Ú¯Ø±ÙˆÙ‡ Ø¢Ù…ÙˆØ²Ø´ÙŠ','Ú¯Ø±ÙˆÙ‡'])
        col_degree = find_col(cols, ['Ù…Ù‚Ø·Ø¹'])
        col_reg = find_col(cols, ['ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÛŒ','ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…ÙŠ','ØªØ¹Ø¯Ø§Ø¯ Ø«Ø¨Øª Ù†Ø§Ù…'])
        col_M = find_col(cols, ['Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹','Ø³Ø§Ø¹Øª Ø´Ø±ÙˆØ¹ Ú©Ù„Ø§Ø³','M','BV'])
        col_N = find_col(cols, ['Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù†','Ø³Ø§Ø¹Øª Ù¾Ø§ÛŒØ§Ù† Ú©Ù„Ø§Ø³','N','BW'])
        
        if col_room is None:
            print(" -> Ø³ØªÙˆÙ† 'Ù…Ú©Ø§Ù†' ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø±Ø¯ Ø´Ø¯.")
            continue
        
        # normalize textual columns
        for c in [col_room, col_course, col_teacher, col_code, col_unit_th, col_unit_pr, col_group, col_degree, col_reg]:
            if c is not None and c in df.columns:
                df[c] = df[c].fillna("").astype(str).str.replace('\u200c','').str.strip()
        # times
        if col_M in df.columns:
            df['_M_min'] = df[col_M].apply(to_minutes)
        else:
            df['_M_min'] = None
        if col_N in df.columns:
            df['_N_min'] = df[col_N].apply(to_minutes)
        else:
            df['_N_min'] = None
        
        # drop exact duplicates (same code, same room, same times)
        keycols = [c for c in [col_code, col_course, col_teacher, col_room, col_M, col_N] if c is not None]
        if keycols:
            df = df.drop_duplicates(subset=keycols)
        
        # determine slots (start at 08:00, end by max end)
        starts = df['_M_min'].dropna().tolist()
        ends = df['_N_min'].dropna().tolist()
        max_end = max(ends) if ends else (20*60)
        slots = build_slots(DAY_START_MIN, max_end)
        slot_labels = [minute_label(s) for s in slots]
        
        # prepare rooms: one row per unique room (exact string)
        rooms = df[col_room].fillna("").astype(str).unique().tolist()
        # build a grid: dict room -> list per slot (None or list of entries)
        grid = {room: [None]*len(slots) for room in rooms}
        
        # fill grid: for each record mark slot indices that fully fit inside [M,N)
        for idx, row in df.iterrows():
            room = str(row[col_room])
            start = row.get('_M_min', None)
            end = row.get('_N_min', None)
            if start is None or end is None:
                continue
            
            # find start_idx: first slot s.t. slots[i] <= start < slots[i]+SLOT_MIN
            start_idx = None
            for i, s in enumerate(slots):
                if s <= start < s + SLOT_MIN:
                    start_idx = i
                    break
            if start_idx is None:
                start_idx = min(range(len(slots)), key=lambda k: abs(slots[k]-start))
            
            # end_idx: last index where slot_start + SLOT_MIN <= end (fully contained)
            end_idx = None
            for i, s in enumerate(slots):
                if s + SLOT_MIN <= end:
                    end_idx = i
            if end_idx is None or end_idx < start_idx:
                continue
            
            # Create unique entry identifier to avoid duplicates
            entry_id = f"{row[col_course] if col_course else ''}|{row[col_teacher] if col_teacher else ''}|{row[col_code] if col_code else ''}"
            
            # Create entry data
            entry_data = {
                'course': row[col_course] if col_course else "",
                'teacher': row[col_teacher] if col_teacher else "",
                'code': row[col_code] if col_code else "",
                'unit_th': row[col_unit_th] if col_unit_th else "",
                'unit_pr': row[col_unit_pr] if col_unit_pr else "",
                'group': row[col_group] if col_group else "",
                'degree': row[col_degree] if col_degree else "",
                'reg': row[col_reg] if col_reg else "",
                'M': row[col_M] if col_M else "",
                'N': row[col_N] if col_N else "",
                'entry_id': entry_id
            }
            
            # assign entry to each slot in range
            for k in range(start_idx, end_idx+1):
                if grid[room][k] is None:
                    grid[room][k] = []
                
                # Check if this exact entry already exists to avoid duplicates
                existing_entry_ids = [e['entry_id'] for e in grid[room][k]]
                if entry_id not in existing_entry_ids:
                    grid[room][k].append(entry_data)
        
        # Create phase2 sheet
        out_name = f"Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ {sheet}"
        out_name = out_name[:31]
        ws = wb.create_sheet(title=out_name)
        
        # Title row merged
        total_cols = 1 + len(slot_labels)
        ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=total_cols)
        title_cell = ws.cell(row=1, column=1, value=f"Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ {sheet}")
        title_cell.font = Font(size=14, bold=True)
        title_cell.alignment = Alignment(horizontal="center", vertical="center")
        
        # header row (slot labels) in row 2
        ws.cell(row=2, column=1, value="Ù…Ú©Ø§Ù† / Ø³Ø§Ø¹Øª").font = Font(bold=True)
        for j, lbl in enumerate(slot_labels, start=2):
            c = ws.cell(row=2, column=j, value=lbl)
            c.alignment = Alignment(horizontal="center", vertical="center")
            c.font = Font(size=9)
        
        # write room rows beginning at row 3
        start_row = 3
        for i, room in enumerate(rooms):
            r = start_row + i
            ws.cell(row=r, column=1, value=room)
            ws.cell(row=r, column=1).alignment = Alignment(horizontal="center", vertical="center")
            ws.row_dimensions[r].height = 22
            
            # merge contiguous slots with same content
            j = 0
            while j < len(slots):
                cell_entries = grid[room][j]
                if not cell_entries:
                    j += 1
                    continue
                
                # Find contiguous slots with identical content
                k = j
                while k+1 < len(slots) and grid[room][k+1] == cell_entries:
                    k += 1
                
                excel_start = 2 + j
                excel_end = 2 + k
                
                # Merge cells
                if excel_end > excel_start:
                    ws.merge_cells(start_row=r, start_column=excel_start, end_row=r, end_column=excel_end)
                
                anchor = ws.cell(row=r, column=excel_start)
                
                # Display content (avoid duplicates)
                unique_entries = []
                seen_entry_ids = set()
                for ent in cell_entries:
                    if ent['entry_id'] not in seen_entry_ids:
                        unique_entries.append(ent)
                        seen_entry_ids.add(ent['entry_id'])
                
                # Format display text - only show unique entries
                display_lines = []
                tooltip_lines = []
                
                for ent in unique_entries:
                    display_line = f"{ent['course']} â€” {ent['teacher']}"
                    display_lines.append(display_line)
                    
                    # Simplified tooltip
                    tooltip_text = (
                        f"Ø¯Ø±Ø³: {ent['course']}\n"
                        f"Ø§Ø³ØªØ§Ø¯: {ent['teacher']}\n"
                        f"Ú©Ø¯: {ent['code']}\n"
                        f"ÙˆØ§Ø­Ø¯: {ent['unit_th']}(Ù†) + {ent['unit_pr']}(Ø¹)\n"
                        f"Ø«Ø¨Øªâ€ŒÙ†Ø§Ù…: {ent['reg']}\n"
                        f"Ø³Ø§Ø¹Øª: {ent['M']} - {ent['N']}"
                    )
                    tooltip_lines.append(tooltip_text)
                
                # Only show unique display lines (avoid duplicates in display)
                unique_display_lines = list(set(display_lines))
                anchor.value = "\n".join(unique_display_lines)
                anchor.alignment = Alignment(wrap_text=True, horizontal="center", vertical="center")
                
                # Add tooltip comment with increased height
                if tooltip_lines:
                    try:
                        comment_text = "\n" + "â”€" * 30 + "\n".join(tooltip_lines)
                        anchor.comment = Comment(comment_text, "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ³Ø§Ø²")
                        anchor.comment.width = 350
                        anchor.comment.height = 200
                    except Exception as e:
                        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ú©Ø§Ù…Ù†Øª: {e}")
                
                # Apply light color based on course name
                if unique_entries:
                    first_course = unique_entries[0]['course']
                    color_hex = get_light_color(first_course)
                    fill = PatternFill(start_color=color_hex, end_color=color_hex, fill_type="solid")
                    anchor.fill = fill
                    
                    # Apply same fill to all merged cells
                    for col in range(excel_start, excel_end + 1):
                        ws.cell(row=r, column=col).fill = fill
                
                j = k + 1
        
        # Adjust column widths
        ws.column_dimensions[get_column_letter(1)].width = 25
        for col_idx in range(2, 2 + len(slot_labels)):
            col_letter = get_column_letter(col_idx)
            ws.column_dimensions[col_letter].width = 8
        
        # center alignment for header area
        for row in ws.iter_rows(min_row=2, max_row=2, min_col=1, max_col=1+len(slot_labels)):
            for c in row:
                c.alignment = Alignment(horizontal="center", vertical="center")
    
    print("Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ")
    wb.save(final_output_file)
    print("âœ… Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

def process_file(file):
    """Process the uploaded file and return download link"""
    temp_phase1 = None
    temp_final = None
    
    try:
        print("ðŸ”¹ Starting file processing...")
        
        # Create temporary files
        with tempfile.NamedTemporaryFile(delete=False, suffix='_phase1.xlsx') as tmp1:
            temp_phase1 = tmp1.name
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='_final.xlsx') as tmp2:
            temp_final = tmp2.name
        
        print(f"ðŸ”¹ Temporary files created: {temp_phase1}, {temp_final}")
        
        # Run phase 1
        print("ðŸ”¹ Starting Phase 1...")
        if phase1_extract_data(file, temp_phase1):
            print("âœ… Phase 1 completed successfully")
            
            # Run phase 2
            print("ðŸ”¹ Starting Phase 2...")
            phase2_create_schedule(temp_phase1, temp_final)
            print("âœ… Phase 2 completed successfully")
            
            # Return the file path, not the bytes data
            print(f"âœ… Processing complete. Final file: {temp_final}")
            return temp_final, "Ø¬Ø¯ÙˆÙ„_Ú©Ù„Ø§Ø³ÛŒ_Ù†Ù‡Ø§ÛŒÛŒ.xlsx"
        else:
            print("âŒ Phase 1 failed")
            return None, "Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø² Ø§ÙˆÙ„"
            
    except Exception as e:
        print(f"âŒ Error in process_file: {str(e)}")
        import traceback
        error_details = traceback.format_exc()
        print(f"ðŸ” Full traceback:\n{error_details}")
        return None, f"Ø®Ø·Ø§: {str(e)}"
    
    finally:
        # Clean up temporary files (except the final one which Gradio will handle)
        if temp_phase1 and os.path.exists(temp_phase1):
            try:
                os.unlink(temp_phase1)
                print("âœ… Phase 1 temp file cleaned up")
            except Exception as e:
                print(f"âš ï¸ Could not delete phase1 temp file: {e}")

# Create the interface with Persian RTL layout
with gr.Blocks(
    title="Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ",
    theme=gr.themes.Soft(),
    css="""
    .container {
        direction: rtl;
        text-align: right;
        font-family: Tahoma;
    }
    """
) as demo:
    
    gr.Markdown("""
    # ðŸŽ“ Ø¨Ø±Ù†Ø§Ù…Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¬Ø¯ÙˆÙ„ Ú©Ù„Ø§Ø³ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡
    **Ù†Ø³Ø®Ù‡ 1 - Ø¢Ø¨Ø§Ù† 1404 - Ù†ÛŒÙ…Ø§ÙˆØ²ÛŒØ±ÛŒ**
    
    Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒØ§Ø± (CSV) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            file_input = gr.File(
                label="ðŸ“ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„",
                file_types=[".csv", ".xlsx"],
                type="filepath"
            )
            
            process_btn = gr.Button(
                "ðŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´",
                variant="primary",
                size="lg"
            )
    
    with gr.Row():
        with gr.Column(scale=1):
            status_display = gr.Textbox(
                label="ÙˆØ¶Ø¹ÛŒØª",
                interactive=False,
                value="Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„...",
                lines=2
            )
            
            download_output = gr.File(
                label="ðŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ",
                file_types=[".xlsx"],
                visible=False
            )
    
    # Process function
    def process_and_update(file):
        if file is None:
            return "Ù„Ø·ÙØ§ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", None
        
        try:
            file_path, filename = process_file(file)
            if file_path and os.path.exists(file_path):
                return "âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!", gr.update(value=file_path, label=filename, visible=True)
            else:
                return f"âŒ {filename}", gr.update(visible=False)
                
        except Exception as e:
            error_msg = f"âŒ Ø®Ø·Ø§: {str(e)}"
            print(f"Final error: {error_msg}")
            return error_msg, gr.update(visible=False)
    
    process_btn.click(
        fn=process_and_update,
        inputs=file_input,
        outputs=[status_display, download_output]
    )
    
    # Add a cleanup trigger when the download is used
    def cleanup_after_download():
        """Clean up files after some time"""
        import time
        time.sleep(60)  # Wait 60 seconds before cleanup
        cleanup_temp_files()
    
    # You can trigger cleanup when new file is uploaded
    file_input.change(
        fn=lambda: cleanup_temp_files(),
        inputs=None,
        outputs=None
    )

if __name__ == "__main__":
    demo.launch()